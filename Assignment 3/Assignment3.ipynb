{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + \"regular/baseline\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data formatting<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "# print(f\"Train shape: {train_images.shape}\")\n",
    "# train_labels = train_labels.reshape(-1, 1)\n",
    "# print(f\"Test shape: {train_labels.shape}\")\n",
    "\n",
    "fig, ax = plt.subplots(2,5)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    im_idx = np.argwhere(train_labels == i)[0]\n",
    "    plottable_image = np.reshape(train_images[im_idx], (28,28))\n",
    "    ax[i].imshow(plottable_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regular CNN<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Baseline<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will serve as the baseline for all the tests of the Regular CNN \n",
    "\n",
    "Batch Size - 32\n",
    "Learning Rate - .001\n",
    "Optimizer - Adam\n",
    "\n",
    "The data for each of these tests is stored in the logs/fit/regular/tests/[learning_rate, batch_size, or optimizer]\n",
    "\n",
    "I will test them in the following order: Learning Rate, Batch Size, Optimizer.\n",
    "\n",
    "Since I will be testing in this order I will apply the best learning rate as the baseline for the batch size tests and the best learning rate + batch size for the optimizer tests\n",
    "\n",
    "If the data shows that I will need to change the learning rate for the batch size and the learning rate + batch size for the optimizers I will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,890</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m394,890\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,890</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,890\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN = 'Regular'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'Adam'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3795\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0675\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0463\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0343\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0262\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 19.4912\n",
      "\n",
      "Regular Baseline\n",
      "\tTest loss: 12.996501922607422\n",
      "\tTest accuracy: 0.9851999878883362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(\"\\nRegular Baseline\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Vary Learning Rates<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1076 - loss: 18.8255\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1043 - loss: 2.3136\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1036 - loss: 2.3166\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1037 - loss: 2.3140\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1034 - loss: 2.3129\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0936 - loss: 30588.1738\n",
      "Regular Learning Rate - 0.1\n",
      "\tTest loss: 32680.748046875\n",
      "\tTest accuracy: 0.09669999778270721\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.3744\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1669\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.1473\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.1397\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9675 - loss: 0.1370\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 47.8924\n",
      "Regular Learning Rate - 0.01\n",
      "\tTest loss: 43.43803024291992\n",
      "\tTest accuracy: 0.968999981880188\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8713 - loss: 0.4033\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0639\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0446\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.0335\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0262\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 16.9248\n",
      "Regular Learning Rate - 0.001\n",
      "\tTest loss: 13.335999488830566\n",
      "\tTest accuracy: 0.9803000092506409\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7440 - loss: 0.9011\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.2008\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9588 - loss: 0.1336\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9696 - loss: 0.1001\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9762 - loss: 0.0755\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 12.3432\n",
      "Regular Learning Rate - 0.0001\n",
      "\tTest loss: 10.173771858215332\n",
      "\tTest accuracy: 0.9779000282287598\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4819 - loss: 2.0530\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.5935\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.4265\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8913 - loss: 0.3721\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.3382\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 47.0256\n",
      "Regular Learning Rate - 1e-05\n",
      "\tTest loss: 41.52690124511719\n",
      "\tTest accuracy: 0.9050999879837036\n"
     ]
    }
   ],
   "source": [
    "learning_rates_arr = [.1,.01, .001, .0001, .00001]\n",
    "\n",
    "for learning_rate in learning_rates_arr:\n",
    "    CNN = 'Regular'\n",
    "    batch_size = 32\n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + f\"regular/learning_rate_tests/{learning_rate}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=5, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "    \n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"Regular Learning Rate - {learning_rate}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Varying Batch Sizes<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.3046\n",
      "Epoch 2/5\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0658\n",
      "Epoch 3/5\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 51ms/step - accuracy: 0.9868 - loss: 0.0452\n",
      "Epoch 4/5\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0364\n",
      "Epoch 5/5\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0319\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 22.0574\n",
      "\n",
      "Regular Batch Size - 8\n",
      "\tTest loss: 20.006681442260742\n",
      "\tTest accuracy: 0.9810000061988831\n",
      "Epoch 1/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.3393\n",
      "Epoch 2/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0646\n",
      "Epoch 3/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0447\n",
      "Epoch 4/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0331\n",
      "Epoch 5/5\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0270\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 13.6013\n",
      "\n",
      "Regular Batch Size - 16\n",
      "\tTest loss: 11.512995719909668\n",
      "\tTest accuracy: 0.9850999712944031\n",
      "Epoch 1/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.3636\n",
      "Epoch 2/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0670\n",
      "Epoch 3/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0464\n",
      "Epoch 4/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0359\n",
      "Epoch 5/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0249\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 15.5800\n",
      "\n",
      "Regular Batch Size - 24\n",
      "\tTest loss: 11.21416187286377\n",
      "\tTest accuracy: 0.9846000075340271\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.3993\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0620\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0416\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0323\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0259\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 14.5666\n",
      "\n",
      "Regular Batch Size - 32\n",
      "\tTest loss: 10.78266716003418\n",
      "\tTest accuracy: 0.9854000210762024\n",
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.5312\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0710\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0485\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0347\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0271\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 8.7097\n",
      "\n",
      "Regular Batch Size - 64\n",
      "\tTest loss: 6.998801231384277\n",
      "\tTest accuracy: 0.9869999885559082\n",
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7986 - loss: 0.6534\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9703 - loss: 0.0945\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0587\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0411\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0345\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 9.9630 \n",
      "\n",
      "Regular Batch Size - 128\n",
      "\tTest loss: 7.899136543273926\n",
      "\tTest accuracy: 0.9854999780654907\n"
     ]
    }
   ],
   "source": [
    "batch_sizes_arr = [8, 16, 24, 32, 64, 128]\n",
    "\n",
    "for batch_size in batch_sizes_arr:\n",
    "    CNN = 'Regular'\n",
    "    learning_rate = .001\n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + f\"regular/batch_size_tests/{batch_size}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=5, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "    \n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\nRegular Batch Size - {batch_size}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Varying Optimizers<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = 'Regular'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'SGD'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate), \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"regular/optimizer_test/{optimizer}\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nRegular Optimizer - {optimizer}\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = 'Regular'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'RMSProp'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate), \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"regular/optimizer_test/{optimizer}\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nRegular Optimizer - {optimizer}\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit/regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Inverted CNN<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Baseline<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = 'Inverted'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'Adam'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(16, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"inverted/baseline\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nInverted Baseline\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_arr = [.1,.01, .001, .0001, .00001]\n",
    "\n",
    "for learning_rate in learning_rates_arr:\n",
    "    CNN = 'Inverted'\n",
    "    batch_size = 32\n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(16, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + f\"inverted/learning_rate_tests/{learning_rate}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=5, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "    \n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\nInverted Learning Rate - {learning_rate}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes_arr = [8, 16, 24,, 32, 64, 128]\n",
    "\n",
    "for batch_size in batch_sizes_arr:\n",
    "    CNN = 'Inverted'\n",
    "    learning_rate = .001\n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(16, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + f\"inverted/batch_size_tests/{batch_size}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=5, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\nInverted Batch Size - {batch_size}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = 'Inverted'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'SGD'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(16, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"inverted/optimizer_tests/SGD\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nInverted Optimizer - {optimizer}\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])\n",
    "\n",
    "CNN = 'Inverted'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'RMSProp'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(16, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=RMSprop(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"inverted/optimizer_tests/RMSProp\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "print('RMSProp')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nInverted Optimizer - {optimizer}\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit/inverted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hourglass<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Baseline<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = 'Hourglass'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'Adam'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"hourglass/baseline\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nHourglass Baseline\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_arr = [.1,.01, .001, .0001, .00001]\n",
    "\n",
    "for learning_rate in learning_rates_arr:\n",
    "    CNN = 'Hourglass'\n",
    "    batch_size = 32\n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + f\"hourglass/learning_rate_tests/{learning_rate}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=5, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "    \n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\Hourglass Learning Rate - {learning_rate}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes_arr = [8, 16, 24,, 32, 64, 128]\n",
    "\n",
    "for batch_size in batch_sizes_arr:\n",
    "    CNN = 'Hourglass'\n",
    "    learning_rate = .001\n",
    "    optimizer = 'Adam'\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + f\"hourglass/batch_size_tests/{batch_size}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=5, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\Hourglass Batch Size - {batch_size}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = 'Hourglass'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'SGD'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"hourglass/optimizer_tests/SGD\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\Hourglass Optimizer - {optimizer}\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])\n",
    "\n",
    "CNN = 'Hourglass'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "optimizer = 'RMSProp'\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu', strides=(2,2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=RMSprop(learning_rate), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + f\"hourglass/optimizer_tests/RMSProp\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "print('RMSProp')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\Hourglass Optimizer - {optimizer}\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load in the CIFAR-10 dataset\n",
    "from keras.datasets import cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(test_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │           \u001b[38;5;34m456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m2,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │        \u001b[38;5;34m48,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m84\u001b[0m)       │        \u001b[38;5;34m10,164\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,006</span> (242.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,006\u001b[0m (242.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,006</span> (242.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,006\u001b[0m (242.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#Layer 1 Convolution layer with 6 kernels and kernel size of 5x5\n",
    "model.add(keras.layers.Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(32,32,3)))\n",
    "\n",
    "#Layer 2 Max pooling layer with a kernel of 2x2 with stride of 2\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#Layer 3 Convolution layer with 16 kernels and kernel size of 5x5\n",
    "model.add(keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'))\n",
    "\n",
    "#Layer 4 Max pooling layer with a kernel of 2x2 with stride of 2\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#Layer 5 Convolution layer with 120 kernels and kernel size of 5x5\n",
    "model.add(keras.layers.Conv2D(120, kernel_size=(5,5), activation='relu'))\n",
    "\n",
    "#Layer 6 Dense layer with 84 neurons\n",
    "model.add(keras.layers.Dense(84, activation='relu'))\n",
    "\n",
    "#Flatten the output of the previous layer\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "#Layer 7 Output Layer with 10 neurons\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=Adam(.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2654 - loss: 1.9969\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4410 - loss: 1.5481\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4917 - loss: 1.4120\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5215 - loss: 1.3249\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5543 - loss: 1.2465\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5744 - loss: 1.2007\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5868 - loss: 1.1595\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6009 - loss: 1.1235\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6154 - loss: 1.0893\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6262 - loss: 1.0617\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 1.0284\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6450 - loss: 1.0023\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.9819\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6626 - loss: 0.9618\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6720 - loss: 0.9331\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6774 - loss: 0.9139\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6829 - loss: 0.8913\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6874 - loss: 0.8822\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6979 - loss: 0.8614\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7002 - loss: 0.8419\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 0.8261\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7114 - loss: 0.8088\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7156 - loss: 0.7932\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7237 - loss: 0.7797\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 0.7643\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6296 - loss: 1.1154\n",
      "\n",
      "LeNet Baseline\n",
      "\tTest loss: 1.1290086507797241\n",
      "\tTest accuracy: 0.6255000233650208\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=25, \n",
    "    batch_size = batch_size,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(\"\\nLeNet Baseline\")\n",
    "print('\\tTest loss:', score[0])\n",
    "print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0986 - loss: 19.3048\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3086\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1015 - loss: 2.3078\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0997 - loss: 2.3092\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.3076\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1010 - loss: 2.3094\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1010 - loss: 2.3084\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0961 - loss: 2.3099\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1025 - loss: 2.3076\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3083\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0975 - loss: 2.3081\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1027 - loss: 2.3084\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1005 - loss: 2.3084\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.3078\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1016 - loss: 2.3083\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0981 - loss: 2.3104\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0983 - loss: 2.3091\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1025 - loss: 2.3072\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0981 - loss: 2.3089\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3081\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1024 - loss: 2.3083\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1011 - loss: 2.3082\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0981 - loss: 2.3081\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 2.3098\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1015 - loss: 2.3080\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3108\n",
      "\n",
      "LeNet Learning Rate - 0.1\n",
      "\tTest loss: 2.310779333114624\n",
      "\tTest accuracy: 0.10000000149011612\n",
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2679 - loss: 1.9615\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4568 - loss: 1.4983\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4901 - loss: 1.4108\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5062 - loss: 1.3760\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5250 - loss: 1.3247\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5370 - loss: 1.2935\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5339 - loss: 1.3025\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5516 - loss: 1.2604\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5589 - loss: 1.2276\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5607 - loss: 1.2357\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5669 - loss: 1.2227\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5716 - loss: 1.2113\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5827 - loss: 1.1851\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5860 - loss: 1.1738\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5924 - loss: 1.1619\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5870 - loss: 1.1687\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5870 - loss: 1.1739\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5932 - loss: 1.1513\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5969 - loss: 1.1436\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5974 - loss: 1.1434\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 1.1355\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5948 - loss: 1.1469\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6038 - loss: 1.1307\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6055 - loss: 1.1343\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6053 - loss: 1.1176\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 1.4411\n",
      "\n",
      "LeNet Learning Rate - 0.01\n",
      "\tTest loss: 1.4605422019958496\n",
      "\tTest accuracy: 0.5206000208854675\n",
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2943 - loss: 1.9353\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4640 - loss: 1.4853\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5102 - loss: 1.3693\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5412 - loss: 1.2841\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5616 - loss: 1.2335\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 1.1815\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5915 - loss: 1.1481\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6051 - loss: 1.1089\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6188 - loss: 1.0684\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6388 - loss: 1.0277\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.9949\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6588 - loss: 0.9727\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6701 - loss: 0.9509\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.9253\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.9107\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6898 - loss: 0.8851\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6889 - loss: 0.8783\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.8494\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7055 - loss: 0.8352\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.8182\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.8051\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7246 - loss: 0.7816\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7287 - loss: 0.7710\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7322 - loss: 0.7543\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.7480\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6500 - loss: 1.0480\n",
      "\n",
      "LeNet Learning Rate - 0.001\n",
      "\tTest loss: 1.0439940690994263\n",
      "\tTest accuracy: 0.6498000025749207\n",
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3043 - loss: 1.8841\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4797 - loss: 1.4286\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5305 - loss: 1.3065\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5663 - loss: 1.2159\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5945 - loss: 1.1388\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6110 - loss: 1.0954\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6177 - loss: 1.0696\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 1.0279\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6503 - loss: 0.9864\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 0.9726\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6597 - loss: 0.9512\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6737 - loss: 0.9207\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.8993\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6941 - loss: 0.8643\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.8458\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7010 - loss: 0.8342\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7131 - loss: 0.8110\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7203 - loss: 0.7897\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 0.7753\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.7738\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.7493\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.7370\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7432 - loss: 0.7130\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7419 - loss: 0.7176\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.6947\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 1.2409\n",
      "\n",
      "LeNet Learning Rate - 0.0025\n",
      "\tTest loss: 1.267059326171875\n",
      "\tTest accuracy: 0.6029999852180481\n",
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1797 - loss: 2.2280\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3230 - loss: 1.8892\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3717 - loss: 1.7724\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3994 - loss: 1.6896\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4179 - loss: 1.6361\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4358 - loss: 1.5784\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4388 - loss: 1.5683\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4525 - loss: 1.5268\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4633 - loss: 1.4984\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4715 - loss: 1.4827\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4769 - loss: 1.4721\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4809 - loss: 1.4487\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4883 - loss: 1.4330\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4922 - loss: 1.4190\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4976 - loss: 1.4013\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5022 - loss: 1.3943\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5075 - loss: 1.3873\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5056 - loss: 1.3756\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5175 - loss: 1.3602\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5214 - loss: 1.3508\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5231 - loss: 1.3430\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5278 - loss: 1.3380\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5304 - loss: 1.3270\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5328 - loss: 1.3142\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5324 - loss: 1.3094\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 1.3317\n",
      "\n",
      "LeNet Learning Rate - 0.0001\n",
      "\tTest loss: 1.3384345769882202\n",
      "\tTest accuracy: 0.5198000073432922\n",
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0998 - loss: 2.3024\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1341 - loss: 2.2906\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2126 - loss: 2.2507\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2339 - loss: 2.1798\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2574 - loss: 2.1081\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2780 - loss: 2.0430\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2903 - loss: 1.9942\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3029 - loss: 1.9564\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3187 - loss: 1.9189\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3303 - loss: 1.8854\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3466 - loss: 1.8523\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3578 - loss: 1.8223\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3671 - loss: 1.7968\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3720 - loss: 1.7783\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3813 - loss: 1.7575\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3880 - loss: 1.7389\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3903 - loss: 1.7222\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4056 - loss: 1.7012\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4023 - loss: 1.6897\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4028 - loss: 1.6812\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4099 - loss: 1.6687\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4115 - loss: 1.6579\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4149 - loss: 1.6472\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4172 - loss: 1.6376\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4205 - loss: 1.6294\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4219 - loss: 1.6276\n",
      "\n",
      "LeNet Learning Rate - 1e-05\n",
      "\tTest loss: 1.6213669776916504\n",
      "\tTest accuracy: 0.42100000381469727\n"
     ]
    }
   ],
   "source": [
    "learning_rates_arr = [.1,.01, .001, .0025, .0001, .00001]\n",
    "\n",
    "for learning_rate in learning_rates_arr:\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(32,32,3)),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        keras.layers.Conv2D(120, kernel_size=(5,5), activation='relu'),\n",
    "        keras.layers.Dense(84, activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=25, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\nLeNet Learning Rate - {learning_rate}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.3362 - loss: 1.7883\n",
      "Epoch 2/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 1.3085\n",
      "Epoch 3/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 1.1773\n",
      "Epoch 4/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 1.0993\n",
      "Epoch 5/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: 1.0390\n",
      "Epoch 6/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 0.9908\n",
      "Epoch 7/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 0.9503\n",
      "Epoch 8/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.9021\n",
      "Epoch 9/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.6910 - loss: 0.8752\n",
      "Epoch 10/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.6993 - loss: 0.8530\n",
      "Epoch 11/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.8247\n",
      "Epoch 12/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.7133 - loss: 0.8120\n",
      "Epoch 13/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.7869\n",
      "Epoch 14/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.7628\n",
      "Epoch 15/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.7401\n",
      "Epoch 16/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.7230\n",
      "Epoch 17/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.7077\n",
      "Epoch 18/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7505 - loss: 0.6971\n",
      "Epoch 19/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.6784\n",
      "Epoch 20/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3494s\u001b[0m 559ms/step - accuracy: 0.7588 - loss: 0.6735\n",
      "Epoch 21/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - accuracy: 0.7634 - loss: 0.6600\n",
      "Epoch 22/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - accuracy: 0.7711 - loss: 0.6447\n",
      "Epoch 23/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 11ms/step - accuracy: 0.7688 - loss: 0.6417\n",
      "Epoch 24/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 14ms/step - accuracy: 0.7777 - loss: 0.6217\n",
      "Epoch 25/25\n",
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 17ms/step - accuracy: 0.7803 - loss: 0.6130\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5961 - loss: 1.4281\n",
      "\n",
      "LeNet Batch Sizes - 8\n",
      "\tTest loss: 1.4556115865707397\n",
      "\tTest accuracy: 0.5983999967575073\n",
      "Epoch 1/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 17ms/step - accuracy: 0.3243 - loss: 1.8315\n",
      "Epoch 2/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 18ms/step - accuracy: 0.5073 - loss: 1.3742\n",
      "Epoch 3/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 18ms/step - accuracy: 0.5576 - loss: 1.2358\n",
      "Epoch 4/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 17ms/step - accuracy: 0.5949 - loss: 1.1428\n",
      "Epoch 5/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - accuracy: 0.6251 - loss: 1.0621\n",
      "Epoch 6/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 18ms/step - accuracy: 0.6436 - loss: 1.0141\n",
      "Epoch 7/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 18ms/step - accuracy: 0.6586 - loss: 0.9676\n",
      "Epoch 8/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 18ms/step - accuracy: 0.6743 - loss: 0.9244\n",
      "Epoch 9/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 18ms/step - accuracy: 0.6825 - loss: 0.8933\n",
      "Epoch 10/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 19ms/step - accuracy: 0.6912 - loss: 0.8650\n",
      "Epoch 11/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 19ms/step - accuracy: 0.7032 - loss: 0.8367\n",
      "Epoch 12/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.7117 - loss: 0.8122\n",
      "Epoch 13/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.7193 - loss: 0.7899\n",
      "Epoch 14/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 18ms/step - accuracy: 0.7265 - loss: 0.7670\n",
      "Epoch 15/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 19ms/step - accuracy: 0.7304 - loss: 0.7613\n",
      "Epoch 16/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.7361 - loss: 0.7380\n",
      "Epoch 17/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.7473 - loss: 0.7141\n",
      "Epoch 18/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 19ms/step - accuracy: 0.7524 - loss: 0.6964\n",
      "Epoch 19/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.7522 - loss: 0.6932\n",
      "Epoch 20/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 20ms/step - accuracy: 0.7637 - loss: 0.6674\n",
      "Epoch 21/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 20ms/step - accuracy: 0.7635 - loss: 0.6620\n",
      "Epoch 22/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 20ms/step - accuracy: 0.7675 - loss: 0.6526\n",
      "Epoch 23/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 20ms/step - accuracy: 0.7720 - loss: 0.6380\n",
      "Epoch 24/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 19ms/step - accuracy: 0.7771 - loss: 0.6233\n",
      "Epoch 25/25\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 20ms/step - accuracy: 0.7852 - loss: 0.5995\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6104 - loss: 1.3328\n",
      "\n",
      "LeNet Batch Sizes - 16\n",
      "\tTest loss: 1.3401373624801636\n",
      "\tTest accuracy: 0.6097000241279602\n",
      "Epoch 1/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.3198 - loss: 1.8344\n",
      "Epoch 2/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.5100 - loss: 1.3508\n",
      "Epoch 3/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.5679 - loss: 1.2092\n",
      "Epoch 4/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.6002 - loss: 1.1133\n",
      "Epoch 5/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.6297 - loss: 1.0390\n",
      "Epoch 6/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6450 - loss: 0.9964\n",
      "Epoch 7/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.6625 - loss: 0.9451\n",
      "Epoch 8/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - accuracy: 0.6793 - loss: 0.9039\n",
      "Epoch 9/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.6861 - loss: 0.8787\n",
      "Epoch 10/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.6992 - loss: 0.8432\n",
      "Epoch 11/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.7104 - loss: 0.8160\n",
      "Epoch 12/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.7157 - loss: 0.7945\n",
      "Epoch 13/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.7280 - loss: 0.7601\n",
      "Epoch 14/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.7374 - loss: 0.7358\n",
      "Epoch 15/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.7475 - loss: 0.7063\n",
      "Epoch 16/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7479 - loss: 0.7023\n",
      "Epoch 17/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7579 - loss: 0.6807\n",
      "Epoch 18/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.7687 - loss: 0.6552\n",
      "Epoch 19/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7707 - loss: 0.6460\n",
      "Epoch 20/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7751 - loss: 0.6207\n",
      "Epoch 21/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.7820 - loss: 0.6068\n",
      "Epoch 22/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7892 - loss: 0.5879\n",
      "Epoch 23/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7965 - loss: 0.5668\n",
      "Epoch 24/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.7973 - loss: 0.5673\n",
      "Epoch 25/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7992 - loss: 0.5492\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6144 - loss: 1.3447\n",
      "\n",
      "LeNet Batch Sizes - 32\n",
      "\tTest loss: 1.3502272367477417\n",
      "\tTest accuracy: 0.6154999732971191\n",
      "Epoch 1/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.3146 - loss: 1.8626\n",
      "Epoch 2/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.4816 - loss: 1.4395\n",
      "Epoch 3/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.5398 - loss: 1.2857\n",
      "Epoch 4/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.5712 - loss: 1.2011\n",
      "Epoch 5/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.5956 - loss: 1.1466\n",
      "Epoch 6/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6130 - loss: 1.0863\n",
      "Epoch 7/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.6305 - loss: 1.0333\n",
      "Epoch 8/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.6458 - loss: 1.0078\n",
      "Epoch 9/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.6555 - loss: 0.9727\n",
      "Epoch 10/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6707 - loss: 0.9343\n",
      "Epoch 11/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.9016\n",
      "Epoch 12/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6911 - loss: 0.8768\n",
      "Epoch 13/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7007 - loss: 0.8478\n",
      "Epoch 14/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7104 - loss: 0.8228\n",
      "Epoch 15/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.8120\n",
      "Epoch 16/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.7744\n",
      "Epoch 17/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7311 - loss: 0.7573\n",
      "Epoch 18/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.7362\n",
      "Epoch 19/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.7140\n",
      "Epoch 20/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.7125\n",
      "Epoch 21/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.6908\n",
      "Epoch 22/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.6712\n",
      "Epoch 23/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7646 - loss: 0.6595\n",
      "Epoch 24/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.6436\n",
      "Epoch 25/25\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.6246\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6172 - loss: 1.2084\n",
      "\n",
      "LeNet Batch Sizes - 64\n",
      "\tTest loss: 1.2222336530685425\n",
      "\tTest accuracy: 0.6177999973297119\n",
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2816 - loss: 1.9327\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4645 - loss: 1.4686\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5082 - loss: 1.3540\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5411 - loss: 1.2805\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5629 - loss: 1.2218\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5798 - loss: 1.1818\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 1.1219\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6163 - loss: 1.0794\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6309 - loss: 1.0397\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6366 - loss: 1.0306\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6519 - loss: 0.9862\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6593 - loss: 0.9645\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6671 - loss: 0.9395\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6802 - loss: 0.9192\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6836 - loss: 0.8958\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6896 - loss: 0.8779\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6961 - loss: 0.8654\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7047 - loss: 0.8364\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7087 - loss: 0.8255\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7184 - loss: 0.7974\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7186 - loss: 0.7974\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7257 - loss: 0.7765\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7297 - loss: 0.7646\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7429 - loss: 0.7321\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 0.7240\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 1.0815\n",
      "\n",
      "LeNet Batch Sizes - 128\n",
      "\tTest loss: 1.0833172798156738\n",
      "\tTest accuracy: 0.6312000155448914\n"
     ]
    }
   ],
   "source": [
    "batch_sizes_arr = [8, 16, 32, 64, 128]\n",
    "\n",
    "for batch_size in batch_sizes_arr:\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(32,32,3)),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        keras.layers.Conv2D(120, kernel_size=(5,5), activation='relu'),\n",
    "        keras.layers.Dense(84, activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(.001), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images, \n",
    "        train_labels, \n",
    "        epochs=25, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\nLeNet Batch Sizes - {batch_size}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3062 - loss: 1.8752\n",
      "Epoch 2/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4877 - loss: 1.4195\n",
      "Epoch 3/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 1.2793\n",
      "Epoch 4/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5749 - loss: 1.1993\n",
      "Epoch 5/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 1.1460\n",
      "Epoch 6/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 1.1014\n",
      "Epoch 7/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 1.0527\n",
      "Epoch 8/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6369 - loss: 1.0267\n",
      "Epoch 9/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6489 - loss: 0.9910\n",
      "Epoch 10/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.9741\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 1.1265\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m     27\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLeNet Batch Sizes - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbatch_size\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    learning_rate = .009\n",
    "    batch_size = 25\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(32,32,3)),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        keras.layers.Conv2D(120, kernel_size=(5,5), activation='relu'),\n",
    "        keras.layers.Dense(84, activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate), \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels, \n",
    "        epochs=10, \n",
    "        batch_size = batch_size,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Evaluate\n",
    "    score = model.evaluate(test_images, test_labels)\n",
    "    print(f\"\\nLeNet Batch Sizes - {batch_size}\")\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
